{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5544b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e36fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8991cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the SpamCollection file\n",
    "df = pd.read_csv('SpamCollection',sep='\\t',names=['Response','Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22ec030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Response                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625ab730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Response                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first 5 Records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c0284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Message                                                            \\\n",
       "           count unique                                                top   \n",
       "Response                                                                     \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    653  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "Response       \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by to find the count of spam and ham messages\n",
    "df.groupby('Response').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d37a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of messages\n",
    "df['length'] = df['Message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4eca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       111\n",
       "1        29\n",
       "2       155\n",
       "3        49\n",
       "4        61\n",
       "       ... \n",
       "5567    160\n",
       "5568     36\n",
       "5569     57\n",
       "5570    125\n",
       "5571     26\n",
       "Name: length, Length: 5572, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e671e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS:\n",
    "# 1. Remove punctuations and stopwords. Split the sentence into words. This process is called tokenization. \n",
    "# 2. Apply CountVectorizer and Transform. This converts the words to a integer or float. This process is called as Feature Extraction.\n",
    "# 3. Apply TF/IDF transform - Term Frequency and Inverse Document Frequency \n",
    "# 4. Split data into train and test\n",
    "# 5. Using Naive Bayes Classification, first train the model with train data.\n",
    "# 6. Test the model and get the prediction.\n",
    "# 7. Compare prediction vs Actual and get the confusion matrix.\n",
    "# 8. Get the accuracy score for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb9fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove punctuations and stopwords\n",
    "def message_text_process(message):   \n",
    "    no_punct = [char for char in message if char not in string.punctuation]\n",
    "    no_punct = ''.join(no_punct)    \n",
    "    return [word for word in no_punct.split() if word.lower() not in stopwords.words('english')]           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdedcbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the above function to see if its working\n",
    "df['Message'].head(5).apply(message_text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f616155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fa89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CountVectorizer - Convert a collection of text documents to a matrix of token counts.\n",
    "vectorization = CountVectorizer(analyzer = message_text_process )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9723b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Go': 2, 'jurong': 10, 'point': 13, 'crazy': 6, 'Available': 0, 'bugis': 5, 'n': 12, 'great': 9, 'world': 15, 'la': 11, 'e': 7, 'buffet': 4, 'Cine': 1, 'got': 8, 'amore': 3, 'wat': 14}\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n"
     ]
    }
   ],
   "source": [
    "# TRIAL ---- try out the Count Vectorizer and Transform for only 1 record to see the output.\n",
    "# try out the count vectorizer for the first record alone\n",
    "bag_of_words_transformer_try = vectorization.fit(df['Message'].head(1))\n",
    "# print out the bag_of_words_transformer\n",
    "print(bag_of_words_transformer_try.vocabulary_)\n",
    "# transform the first record alone\n",
    "message_try = bag_of_words_transformer_try.transform(df['Message'].head(1))\n",
    "print(message_try)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbdf52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n",
      "  (0, 1110)\t1\n",
      "  (0, 1483)\t1\n",
      "  (0, 2060)\t1\n",
      "  (0, 4653)\t1\n",
      "  (0, 5217)\t1\n",
      "  (0, 5218)\t1\n",
      "  (0, 5769)\t1\n",
      "  (0, 6217)\t1\n",
      "  (0, 6906)\t1\n",
      "  (0, 6937)\t1\n",
      "  (0, 7555)\t1\n",
      "  (0, 7668)\t1\n",
      "  (0, 8336)\t1\n",
      "  (0, 8917)\t1\n",
      "  (0, 10965)\t1\n",
      "  (0, 11163)\t1\n",
      "  (1, 2451)\t1\n",
      "  (1, 3064)\t1\n",
      "  (1, 7701)\t1\n",
      "  (1, 8590)\t1\n",
      "  (1, 10698)\t1\n",
      "  (1, 11072)\t1\n",
      "  (2, 73)\t1\n",
      "  (2, 423)\t1\n",
      "  (2, 430)\t1\n",
      "  :\t:\n",
      "  (5568, 6691)\t1\n",
      "  (5568, 6882)\t1\n",
      "  (5568, 7159)\t1\n",
      "  (5568, 11418)\t1\n",
      "  (5569, 3228)\t1\n",
      "  (5569, 3721)\t1\n",
      "  (5569, 8252)\t1\n",
      "  (5569, 10199)\t1\n",
      "  (5570, 4508)\t1\n",
      "  (5570, 5055)\t1\n",
      "  (5570, 5251)\t1\n",
      "  (5570, 6282)\t1\n",
      "  (5570, 6699)\t1\n",
      "  (5570, 6799)\t1\n",
      "  (5570, 6984)\t1\n",
      "  (5570, 7287)\t1\n",
      "  (5570, 7394)\t1\n",
      "  (5570, 7800)\t1\n",
      "  (5570, 8420)\t1\n",
      "  (5570, 9915)\t1\n",
      "  (5570, 10787)\t1\n",
      "  (5570, 11006)\t1\n",
      "  (5571, 3431)\t1\n",
      "  (5571, 8348)\t1\n",
      "  (5571, 10648)\t1\n"
     ]
    }
   ],
   "source": [
    "#Apply CountVectorizer to the entire df\n",
    "bag_of_words_transformer = vectorization.fit(df['Message'])\n",
    "print(len(bag_of_words_transformer.vocabulary_))\n",
    "message = bag_of_words_transformer.transform(df['Message'])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06bdc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Tf/IDF\n",
    "#TF/IDF transform - eg\n",
    "#Consider a document containing 100 words wherein the word cat appears 3 times. \n",
    "#The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. \n",
    "#Now, assume we have 10 million documents and the word cat appears in one thousand of these. \n",
    "#Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. \n",
    "#Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "662ccc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25\n",
      " 0.25 0.25]\n"
     ]
    }
   ],
   "source": [
    "#try out the tfidf for only 1 record\n",
    "tfidf_transformer_try = TfidfTransformer().fit(message_try)\n",
    "message_tfidf_try = tfidf_transformer_try.transform(message_try)\n",
    "print(message_tfidf_try.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a4dbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23026686, 0.19073429, 0.24704652, ..., 0.53921812, 0.48542915,\n",
       "       0.68818773])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Tf/IDF for the whole df\n",
    "tfidf_transformer = TfidfTransformer().fit(message)\n",
    "message_tfidf = tfidf_transformer.transform(message)\n",
    "message_tfidf.shape\n",
    "message_tfidf.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba036ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train(70%) and test(30%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(message_tfidf, df['Response'], test_size=0.30, random_state = 50)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5795e4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2696     ham\n",
       "1659    spam\n",
       "4829     ham\n",
       "5319     ham\n",
       "1394     ham\n",
       "        ... \n",
       "3330     ham\n",
       "70       ham\n",
       "132      ham\n",
       "2014    spam\n",
       "1931     ham\n",
       "Name: Response, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e81b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes to detect spam\n",
    "# Train the model first using train data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6385a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model using test data. Make predictions\n",
    "predictions = spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b34607a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted ['spam' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "print('predicted', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e373cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual 3409    spam\n",
      "2103     ham\n",
      "2665     ham\n",
      "3239     ham\n",
      "1205    spam\n",
      "        ... \n",
      "1302     ham\n",
      "69       ham\n",
      "4928     ham\n",
      "2944     ham\n",
      "629     spam\n",
      "Name: Response, Length: 1672, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('actual', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0f1d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1469    0]\n",
      " [  57  146]]\n"
     ]
    }
   ],
   "source": [
    "# Compare Predicted vs Actual using Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea5aea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d964abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9795d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659090909090909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ce9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
